# @package _global_

defaults:
  - override /data_collectors: dynamics
  - override /interaction/environment: video_folders
  - override /interaction/agent: curiosity_image_multi_step_imagination
  - override /models: learn_only_sioconv_large
  - override /trainers: forward_dynamics_with_action_reward

shared:
  image_height: 144
  image_width: 144
  frame_limit: ${python.eval:"int(10 * ${cvt_time_str:4h})"} # 10FPS, 4時間分. 6サンプルで24時間分

interaction:
  agent:
    max_imagination_steps: 50 # 5 sec
  environment:
    observation_generator:
      folder_frame_limits: ${shared.frame_limit}
      folder_paths:
        - ${paths.data_dir}/random_observation_action_log/2024-08-26_12-55-45/io/video_recordings
        - ${paths.data_dir}/random_observation_action_log/2024-08-26_13-00-14/io/video_recordings
        - ${paths.data_dir}/random_observation_action_log/2024-08-26_13-04-15/io/video_recordings
        - ${paths.data_dir}/random_observation_action_log/2024-08-26_13-08-31/io/video_recordings
        - ${paths.data_dir}/random_observation_action_log/2024-08-27_09-28-27/io/video_recordings
        - ${paths.data_dir}/random_observation_action_log/2024-08-27_09-31-50/io/video_recordings

models:
  i_jepa_target_encoder:
    inference_thread_only: True
    parameter_file: null # 学習済モデルをセットする。
    model:
      patch_size: 12
      embed_dim: 648
      out_dim: 32
      depth: 12
      num_heads: 9
  i_jepa_target_visualization_decoder:
    inference_thread_only: True
    parameter_file: null # 学習済モデルをセットする
  policy:
    model:
      file_max_rows: ${shared.frame_limit}
      column_headers:
        - "MoveVertical"
        - "MoveHorizontal"
        - "LookHorizontal"
        - "Jump"
        - "Run"
      file_paths:
        - ${paths.data_dir}/random_observation_action_log/2024-08-26_12-55-45/io/action_log.csv
        - ${paths.data_dir}/random_observation_action_log/2024-08-26_13-00-14/io/action_log.csv
        - ${paths.data_dir}/random_observation_action_log/2024-08-26_13-04-15/io/action_log.csv
        - ${paths.data_dir}/random_observation_action_log/2024-08-26_13-08-31/io/action_log.csv
        - ${paths.data_dir}/random_observation_action_log/2024-08-27_09-28-27/io/action_log.csv
        - ${paths.data_dir}/random_observation_action_log/2024-08-27_09-31-50/io/action_log.csv

data_collectors:
  forward_dynamics_trajectory:
    max_len: ${python.eval:"20 * ${trainers.forward_dynamics.partial_dataloader.batch_size}"}
    key_list:
      - "embed_observation" # 学習済Observation Encoderの出力を使う
      - "hidden"
      - "action"
      - "reward"

trainers:
  forward_dynamics:
    observation_encoder_name: null # embed observationを直接使う
    max_epochs: 1
    partial_dataloader:
      batch_size: ${python.eval:"256 + 1"} # 学習する系列長. +1することでバッチから1ステップ先の予測対象データを抜き出す。
    minimum_new_data_count: 128

task_name: "learn_only_sioconv_large"
