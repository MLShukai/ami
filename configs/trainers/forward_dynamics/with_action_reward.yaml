_target_: ami.trainers.forward_dynamics_trainer.ForwardDynamicsWithActionRewardTrainer

partial_dataloader:
  _target_: torch.utils.data.DataLoader
  _partial_: true
  shuffle: false

partial_sampler:
  _target_: ami.trainers.components.random_time_series_sampler.RandomTimeSeriesSampler
  _partial_: true
  sequence_length: ${python.eval:8+1} # +1 to generate future target data.
  max_samples: 256 # For dataset size 2048

partial_optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 1e-4
  betas: [0.9, 0.999]

logger:
  _target_: ami.tensorboard_loggers.StepIntervalLogger
  log_dir: ${paths.tensorboard_dir}/forward_dynamics
  log_every_n_steps: 1

obs_loss_coef: 1.0
action_loss_coef: 1.0
reward_loss_coef: 0.0 # 2024/09/16 default false.
observation_encoder_name: image_encoder
device: ${devices.0}
max_epochs: 3
minimum_dataset_size: ${.partial_sampler.sequence_length}
minimum_new_data_count: 128 # From primitive AMI
gradient_clip_norm: 5
