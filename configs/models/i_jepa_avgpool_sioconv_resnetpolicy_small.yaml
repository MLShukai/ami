image_encoder: i_jepa_target_encoder # Alias for ImageEncodingAgent.

i_jepa_target_encoder:
  _target_: ami.models.model_wrapper.ModelWrapper
  default_device: ${devices.0}
  has_inference: True
  inference_forward:
    _target_: ami.models.bool_mask_i_jepa.EncoderInferAveragePool
    n_patches:
      - ${python.eval:"${shared.image_height} // ${models.i_jepa_target_encoder.model.patch_size}"}
      - ${python.eval:"${shared.image_width} // ${models.i_jepa_target_encoder.model.patch_size}"}
    kernel_size: 1
    stride: null
  model:
    _target_: ami.models.bool_mask_i_jepa.BoolMaskIJEPAEncoder
    img_size:
      - ${shared.image_height} # Assuming 84
      - ${shared.image_width} # Assuming 84
    in_channels: ${shared.image_channels} # Assume 3
    patch_size: 12
    embed_dim: 216
    out_dim: 32 # 1 / 13.5
    depth: 6
    num_heads: 3
    mlp_ratio: 4.0

i_jepa_context_encoder:
  _target_: ami.models.model_wrapper.ModelWrapper
  default_device: ${devices.0}
  has_inference: False
  model: ${..i_jepa_target_encoder.model}

i_jepa_predictor:
  _target_: ami.models.model_wrapper.ModelWrapper
  default_device: ${devices.0}
  has_inference: False
  model:
    _target_: ami.models.bool_mask_i_jepa.BoolTargetIJEPAPredictor
    n_patches:
      - ${python.eval:"${shared.image_height} // ${models.i_jepa_target_encoder.model.patch_size}"}
      - ${python.eval:"${shared.image_width} // ${models.i_jepa_target_encoder.model.patch_size}"}
    context_encoder_out_dim: ${models.i_jepa_target_encoder.model.out_dim}
    hidden_dim: 108
    depth: 6
    num_heads: 2

forward_dynamics:
  _target_: ami.models.model_wrapper.ModelWrapper
  default_device: ${devices.0}
  has_inference: True
  model:
    _target_: ami.models.forward_dynamics.ForwardDynamcisWithActionReward
    observation_flatten:
      _target_: ami.models.components.stacked_features.LerpStackedFeatures
      dim_in: ${models.i_jepa_target_encoder.model.out_dim}
      dim_out: 1024
      num_stack: ${python.eval:"(${models.i_jepa_predictor.model.n_patches.0} // ${models.i_jepa_target_encoder.inference_forward.kernel_size}) * (${models.i_jepa_predictor.model.n_patches.1} // ${models.i_jepa_target_encoder.inference_forward.kernel_size})"}
    action_flatten:
      _target_: ami.models.components.multi_embeddings.MultiEmbeddings
      choices_per_category:
        _target_: hydra.utils.get_object
        path: ami.interactions.environments.actuators.vrchat_osc_discrete_actuator.ACTION_CHOICES_PER_CATEGORY
      embedding_dim: 8
      do_flatten: True
    obs_action_projection:
      _target_: torch.nn.Linear
      # action_embedding_dim * num_action_choices + obs_embedding_dim
      in_features: ${python.eval:"${..action_flatten.embedding_dim} * 5 + ${..observation_flatten.dim_out}"}
      out_features: ${..core_model.dim}
    core_model:
      _target_: ami.models.components.sioconv.SioConv
      depth: 6
      dim: 1024
      num_head: 8
      dim_ff_hidden: ${python.eval:"${.dim} * 2"}
      chunk_size: 512
      dropout: 0.1
    obs_hat_dist_head:
      # _target_: ami.models.components.stacked_features.ToStackedFeaturesMDN
      # dim_in: ${..core_model.dim}
      # dim_out: ${models.i_jepa_target_encoder.model.out_dim}
      # num_stack: ${..observation_flatten.num_stack}
      # num_components: 8
      # eps: 0.01
      _target_: torch.nn.Sequential
      _args_:
        - _target_: ami.models.components.stacked_features.ToStackedFeatures
          dim_in: ${....core_model.dim}
          dim_out: ${models.i_jepa_target_encoder.model.out_dim}
          num_stack: ${....observation_flatten.num_stack}
        - _target_: ami.models.components.fully_connected_fixed_std_normal.FullyConnectedFixedStdNormal
          dim_in: ${..0.dim_out}
          dim_out: ${models.i_jepa_target_encoder.model.out_dim}
          normal_cls: Deterministic
    action_hat_dist_head:
      _target_: ami.models.components.discrete_policy_head.DiscretePolicyHead
      dim_in: ${..core_model.dim}
      action_choices_per_category:
        _target_: hydra.utils.get_object
        path: ami.interactions.environments.actuators.vrchat_osc_discrete_actuator.ACTION_CHOICES_PER_CATEGORY
    reward_hat_dist_head:
      _target_: ami.models.components.mixture_desity_network.NormalMixtureDensityNetwork
      in_features: ${..core_model.dim}
      out_features: 1
      num_components: 8
      squeeze_feature_dim: True

policy_value:
  _target_: ami.models.model_wrapper.ModelWrapper
  default_device: ${devices.0}
  has_inference: True
  model:
    _target_: ami.models.policy_value_common_net.PolicyValueCommonNet
    observation_projection:
      _target_: ami.models.components.stacked_features.LerpStackedFeatures
      dim_in: ${models.i_jepa_target_encoder.model.out_dim}
      dim_out: 512
      num_stack: ${models.forward_dynamics.model.observation_flatten.num_stack}
    forward_dynamics_hidden_projection:
      _target_: ami.models.policy_value_common_net.LerpStackedHidden
      dim: ${models.forward_dynamics.model.core_model.dim}
      depth: ${models.forward_dynamics.model.core_model.depth}
      num_head: ${models.forward_dynamics.model.core_model.num_head}
    observation_hidden_projection:
      _target_: ami.models.policy_value_common_net.ConcatFlattenedObservationAndLerpedHidden
      dim_obs: ${..observation_projection.dim_out}
      dim_hidden: ${models.forward_dynamics.model.core_model.dim}
      dim_out: 512
    core_model:
      _target_: ami.models.components.resnet.ResNetFF
      dim: ${..observation_hidden_projection.dim_out}
      dim_hidden: 512
      depth: 4
    policy_head:
      _target_: ami.models.components.discrete_policy_head.DiscretePolicyHead
      dim_in: ${..observation_hidden_projection.dim_out}
      action_choices_per_category:
        _target_: hydra.utils.get_object
        path: ami.interactions.environments.actuators.vrchat_osc_discrete_actuator.ACTION_CHOICES_PER_CATEGORY
    value_head:
      _target_: ami.models.components.fully_connected_value_head.FullyConnectedValueHead
      dim_in: ${..observation_hidden_projection.dim_out}
      squeeze_value_dim: True
